{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 07: TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "foo bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'over', 'with', 'about', 'some', 'like', 'that', 'while', 'more', 'i', 'their', 'this', 'but', 'want', 'who', 'for', 'write', 'an', 'what', 'try', 'we', 'and', 'feel', 'can', 'get', 'same', 'it', 'which', 'both', 'my', 'not', 'just', 'one', 'handle', 'new', 'out', 'there', 'to', 'us', 'use', 'at', 'when', 'then', \"n't\", 'now', 'they', 'you', 'your', 'come', 'in', 'since', 'up', 'of', 'each', 'have', 'all', 'see', 'as', 'next', 'by', 'the', 'be', 'how', 'do', 'from', 'go', 'if', 'its', 'much', 'or', 'our', 'find', 'than', 'a', 'few', 'around', 'let', 'such', 'take', 'other', 'where', 'also', 'so', 'on', 'two'}\n"
     ]
    }
   ],
   "source": [
    "import pynlp\n",
    "\n",
    "stopwords = pynlp.load_stopwords(\"stop.txt\")\n",
    "print(stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "foo bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WordNode(raw='Almost', root='almost', pos='RB')\n",
      "WordNode(raw='a', root='a', pos='DT')\n",
      "WordNode(raw='year', root='year', pos='NN')\n",
      "WordNode(raw='ago', root='ago', pos='RB')\n",
      "WordNode(raw=',', root=',', pos='.')\n",
      "WordNode(raw='we', root='we', pos='PRP')\n",
      "WordNode(raw='published', root='publish', pos='VBD')\n",
      "WordNode(raw='our', root='our', pos='PRP$')\n",
      "WordNode(raw='now-annual', root='now-annual', pos='JJ')\n",
      "WordNode(raw='landscape', root='landscape', pos='NN')\n",
      "WordNode(raw='of', root='of', pos='IN')\n",
      "WordNode(raw='machine', root='machine', pos='NN')\n",
      "WordNode(raw='intelligence', root='intelligence', pos='NN')\n",
      "WordNode(raw='companies', root='company', pos='NNS')\n",
      "WordNode(raw=',', root=',', pos='.')\n",
      "WordNode(raw='and', root='and', pos='CC')\n",
      "WordNode(raw='goodness', root='goodness', pos='NN')\n",
      "WordNode(raw='have', root='have', pos='VBP')\n",
      "WordNode(raw='we', root='we', pos='PRP')\n",
      "WordNode(raw='seen', root='see', pos='VBN')\n",
      "WordNode(raw='a', root='a', pos='DT')\n",
      "WordNode(raw='lot', root='lot', pos='NN')\n",
      "WordNode(raw='of', root='of', pos='IN')\n",
      "WordNode(raw='activity', root='activity', pos='NN')\n",
      "WordNode(raw='since', root='since', pos='IN')\n",
      "WordNode(raw='then', root='then', pos='RB')\n",
      "WordNode(raw='.', root='.', pos='.')\n",
      "WordNode(raw='This', root='this', pos='DT')\n",
      "WordNode(raw='year', root='year', pos='NN')\n",
      "WordNode(raw=\"'s\", root=\"'s\", pos='.')\n",
      "WordNode(raw='landscape', root='landscape', pos='NN')\n",
      "WordNode(raw='has', root='have', pos='VBZ')\n",
      "WordNode(raw='a', root='a', pos='DT')\n",
      "WordNode(raw='third', root='third', pos='JJ')\n",
      "WordNode(raw='more', root='more', pos='JJR')\n",
      "WordNode(raw='companies', root='company', pos='NNS')\n",
      "WordNode(raw='than', root='than', pos='IN')\n",
      "WordNode(raw='our', root='our', pos='PRP$')\n",
      "WordNode(raw='first', root='first', pos='JJ')\n",
      "WordNode(raw='one', root='one', pos='NN')\n",
      "WordNode(raw='did', root='do', pos='VBD')\n",
      "WordNode(raw='two', root='two', pos='CD')\n",
      "WordNode(raw='years', root='year', pos='NNS')\n",
      "WordNode(raw='ago', root='ago', pos='RB')\n",
      "WordNode(raw=',', root=',', pos='.')\n",
      "WordNode(raw='and', root='and', pos='CC')\n",
      "WordNode(raw='it', root='it', pos='PRP')\n",
      "WordNode(raw='feels', root='feel', pos='VBZ')\n",
      "WordNode(raw='even', root='even', pos='RB')\n",
      "WordNode(raw='more', root='more', pos='RBR')\n",
      "WordNode(raw='futile', root='futile', pos='JJ')\n",
      "WordNode(raw='to', root='to', pos='TO')\n",
      "WordNode(raw='try', root='try', pos='VB')\n",
      "WordNode(raw='to', root='to', pos='TO')\n",
      "WordNode(raw='be', root='be', pos='VB')\n",
      "WordNode(raw='comprehensive', root='comprehensive', pos='JJ')\n",
      "WordNode(raw=',', root=',', pos='.')\n",
      "WordNode(raw='since', root='since', pos='IN')\n",
      "WordNode(raw='this', root='this', pos='DT')\n",
      "WordNode(raw='just', root='just', pos='RB')\n",
      "WordNode(raw='scratches', root='scratch', pos='VBZ')\n",
      "WordNode(raw='the', root='the', pos='DT')\n",
      "WordNode(raw='surface', root='surface', pos='NN')\n",
      "WordNode(raw='of', root='of', pos='IN')\n",
      "WordNode(raw='all', root='all', pos='DT')\n",
      "WordNode(raw='of', root='of', pos='IN')\n",
      "WordNode(raw='the', root='the', pos='DT')\n",
      "WordNode(raw='activity', root='activity', pos='NN')\n",
      "WordNode(raw='out', root='out', pos='IN')\n",
      "WordNode(raw='there', root='there', pos='RB')\n",
      "WordNode(raw='.', root='.', pos='.')\n",
      "WordNode(raw='As', root='as', pos='IN')\n",
      "WordNode(raw='has', root='have', pos='VBZ')\n",
      "WordNode(raw='been', root='be', pos='VBN')\n",
      "WordNode(raw='the', root='the', pos='DT')\n",
      "WordNode(raw='case', root='case', pos='NN')\n",
      "WordNode(raw='for', root='for', pos='IN')\n",
      "WordNode(raw='the', root='the', pos='DT')\n",
      "WordNode(raw='last', root='last', pos='JJ')\n",
      "WordNode(raw='couple', root='couple', pos='NN')\n",
      "WordNode(raw='of', root='of', pos='IN')\n",
      "WordNode(raw='years', root='year', pos='NNS')\n",
      "WordNode(raw=',', root=',', pos='.')\n",
      "WordNode(raw='our', root='our', pos='PRP$')\n",
      "WordNode(raw='fund', root='fund', pos='NN')\n",
      "WordNode(raw='still', root='still', pos='RB')\n",
      "WordNode(raw='obsesses', root='obsess', pos='VBZ')\n",
      "WordNode(raw='over', root='over', pos='IN')\n",
      "WordNode(raw='``', root='``', pos='.')\n",
      "WordNode(raw='problem', root='problem', pos='NN')\n",
      "WordNode(raw='first', root='first', pos='RB')\n",
      "WordNode(raw=\"''\", root=\"''\", pos='.')\n",
      "WordNode(raw='machine', root='machine', pos='NN')\n",
      "WordNode(raw='intelligence', root='intelligence', pos='NN')\n",
      "WordNode(raw='--', root='--', pos='.')\n",
      "WordNode(raw='we', root='we', pos='PRP')\n",
      "WordNode(raw=\"'ve\", root=\"'ve\", pos='.')\n",
      "WordNode(raw='invested', root='invest', pos='VBN')\n",
      "WordNode(raw='in', root='in', pos='IN')\n",
      "WordNode(raw='35', root='35', pos='CD')\n",
      "WordNode(raw='machine', root='machine', pos='NN')\n",
      "WordNode(raw='intelligence', root='intelligence', pos='NN')\n",
      "WordNode(raw='companies', root='company', pos='NNS')\n",
      "WordNode(raw='solving', root='solve', pos='VBG')\n",
      "WordNode(raw='35', root='35', pos='CD')\n",
      "WordNode(raw='meaningful', root='meaningful', pos='JJ')\n",
      "WordNode(raw='problems', root='problem', pos='NNS')\n",
      "WordNode(raw='in', root='in', pos='IN')\n",
      "WordNode(raw='areas', root='area', pos='NNS')\n",
      "WordNode(raw='from', root='from', pos='IN')\n",
      "WordNode(raw='security', root='security', pos='NN')\n",
      "WordNode(raw='to', root='to', pos='TO')\n",
      "WordNode(raw='recruiting', root='recruit', pos='VBG')\n",
      "WordNode(raw='to', root='to', pos='TO')\n",
      "WordNode(raw='software', root='software', pos='NN')\n",
      "WordNode(raw='development', root='development', pos='NN')\n",
      "WordNode(raw='.', root='.', pos='.')\n",
      "WordNode(raw='(', root='(', pos='.')\n",
      "WordNode(raw='Our', root='our', pos='PRP$')\n",
      "WordNode(raw='fund', root='fund', pos='NN')\n",
      "WordNode(raw='focuses', root='focus', pos='VBZ')\n",
      "WordNode(raw='on', root='on', pos='IN')\n",
      "WordNode(raw='the', root='the', pos='DT')\n",
      "WordNode(raw='future', root='future', pos='NN')\n",
      "WordNode(raw='of', root='of', pos='IN')\n",
      "WordNode(raw='work', root='work', pos='NN')\n",
      "WordNode(raw=',', root=',', pos='.')\n",
      "WordNode(raw='so', root='so', pos='RB')\n",
      "WordNode(raw='there', root='there', pos='EX')\n",
      "WordNode(raw='are', root='be', pos='VBP')\n",
      "WordNode(raw='some', root='some', pos='DT')\n",
      "WordNode(raw='machine', root='machine', pos='NN')\n",
      "WordNode(raw='intelligence', root='intelligence', pos='NN')\n",
      "WordNode(raw='domains', root='domains', pos='VBZ')\n",
      "WordNode(raw='where', root='where', pos='WRB')\n",
      "WordNode(raw='we', root='we', pos='PRP')\n",
      "WordNode(raw='invest', root='invest', pos='VBP')\n",
      "WordNode(raw='more', root='more', pos='JJR')\n",
      "WordNode(raw='than', root='than', pos='IN')\n",
      "WordNode(raw='others', root='others', pos='NNS')\n",
      "WordNode(raw='.', root='.', pos='.')\n",
      "WordNode(raw=')', root=')', pos='.')\n",
      "WordNode(raw='At', root='at', pos='IN')\n",
      "WordNode(raw='the', root='the', pos='DT')\n",
      "WordNode(raw='same', root='same', pos='JJ')\n",
      "WordNode(raw='time', root='time', pos='NN')\n",
      "WordNode(raw=',', root=',', pos='.')\n",
      "WordNode(raw='the', root='the', pos='DT')\n",
      "WordNode(raw='hype', root='hype', pos='NN')\n",
      "WordNode(raw='around', root='around', pos='RP')\n",
      "WordNode(raw='machine', root='machine', pos='NN')\n",
      "WordNode(raw='intelligence', root='intelligence', pos='NN')\n",
      "WordNode(raw='methods', root='method', pos='NNS')\n",
      "WordNode(raw='continues', root='continue', pos='VBZ')\n",
      "WordNode(raw='to', root='to', pos='TO')\n",
      "WordNode(raw='grow', root='grow', pos='VB')\n",
      "WordNode(raw=':', root=':', pos='.')\n",
      "WordNode(raw='the', root='the', pos='DT')\n",
      "WordNode(raw='words', root='word', pos='NNS')\n",
      "WordNode(raw='``', root='``', pos='.')\n",
      "WordNode(raw='deep', root='deep', pos='JJ')\n",
      "WordNode(raw='learning', root='learning', pos='NN')\n",
      "WordNode(raw=\"''\", root=\"''\", pos='.')\n",
      "WordNode(raw='now', root='now', pos='RB')\n",
      "WordNode(raw='equally', root='equally', pos='RB')\n",
      "WordNode(raw='represent', root='represent', pos='VBP')\n",
      "WordNode(raw='a', root='a', pos='DT')\n",
      "WordNode(raw='series', root='series', pos='NN')\n",
      "WordNode(raw='of', root='of', pos='IN')\n",
      "WordNode(raw='meaningful', root='meaningful', pos='JJ')\n",
      "WordNode(raw='breakthroughs', root='breakthrough', pos='NNS')\n",
      "WordNode(raw='(', root='(', pos='.')\n",
      "WordNode(raw='wonderful', root='wonderful', pos='JJ')\n",
      "WordNode(raw=')', root=')', pos='.')\n",
      "WordNode(raw='but', root='but', pos='CC')\n",
      "WordNode(raw='also', root='also', pos='RB')\n",
      "WordNode(raw='a', root='a', pos='DT')\n",
      "WordNode(raw='hyped', root='hyped', pos='JJ')\n",
      "WordNode(raw='phrase', root='phrase', pos='NN')\n",
      "WordNode(raw='like', root='like', pos='IN')\n",
      "WordNode(raw='``', root='``', pos='.')\n",
      "WordNode(raw='big', root='big', pos='JJ')\n",
      "WordNode(raw='data', root='data', pos='NNS')\n",
      "WordNode(raw=\"''\", root=\"''\", pos='.')\n",
      "WordNode(raw='(', root='(', pos='.')\n",
      "WordNode(raw='not', root='not', pos='RB')\n",
      "WordNode(raw='so', root='so', pos='RB')\n",
      "WordNode(raw='good', root='good', pos='JJ')\n",
      "WordNode(raw='!', root='!', pos='.')\n",
      "WordNode(raw=')', root=')', pos='.')\n",
      "WordNode(raw='.', root='.', pos='.')\n",
      "WordNode(raw='We', root='we', pos='PRP')\n",
      "WordNode(raw='care', root='care', pos='VBP')\n",
      "WordNode(raw='about', root='about', pos='IN')\n",
      "WordNode(raw='whether', root='whether', pos='IN')\n",
      "WordNode(raw='a', root='a', pos='DT')\n",
      "WordNode(raw='founder', root='founder', pos='NN')\n",
      "WordNode(raw='uses', root='use', pos='VBZ')\n",
      "WordNode(raw='the', root='the', pos='DT')\n",
      "WordNode(raw='right', root='right', pos='JJ')\n",
      "WordNode(raw='method', root='method', pos='NN')\n",
      "WordNode(raw='to', root='to', pos='TO')\n",
      "WordNode(raw='solve', root='solve', pos='VB')\n",
      "WordNode(raw='a', root='a', pos='DT')\n",
      "WordNode(raw='problem', root='problem', pos='NN')\n",
      "WordNode(raw=',', root=',', pos='.')\n",
      "WordNode(raw='not', root='not', pos='RB')\n",
      "WordNode(raw='the', root='the', pos='DT')\n",
      "WordNode(raw='fanciest', root='fanciest', pos='JJS')\n",
      "WordNode(raw='one', root='one', pos='NN')\n",
      "WordNode(raw='.', root='.', pos='.')\n",
      "WordNode(raw='We', root='we', pos='PRP')\n",
      "WordNode(raw='favor', root='favor', pos='VBP')\n",
      "WordNode(raw='those', root='those', pos='DT')\n",
      "WordNode(raw='who', root='who', pos='WP')\n",
      "WordNode(raw='apply', root='apply', pos='VBP')\n",
      "WordNode(raw='technology', root='technology', pos='NN')\n",
      "WordNode(raw='thoughtfully', root='thoughtfully', pos='RB')\n",
      "WordNode(raw='.', root='.', pos='.')\n",
      "WordNode(raw='What', root='what', pos='WP')\n",
      "WordNode(raw=\"'s\", root=\"'s\", pos='.')\n",
      "WordNode(raw='the', root='the', pos='DT')\n",
      "WordNode(raw='biggest', root='biggest', pos='JJS')\n",
      "WordNode(raw='change', root='change', pos='NN')\n",
      "WordNode(raw='in', root='in', pos='IN')\n",
      "WordNode(raw='the', root='the', pos='DT')\n",
      "WordNode(raw='last', root='last', pos='JJ')\n",
      "WordNode(raw='year', root='year', pos='NN')\n",
      "WordNode(raw='?', root='?', pos='.')\n",
      "WordNode(raw='We', root='we', pos='PRP')\n",
      "WordNode(raw='are', root='be', pos='VBP')\n",
      "WordNode(raw='getting', root='get', pos='VBG')\n",
      "WordNode(raw='inbound', root='inbound', pos='JJ')\n",
      "WordNode(raw='inquiries', root='inquiry', pos='NNS')\n",
      "WordNode(raw='from', root='from', pos='IN')\n",
      "WordNode(raw='a', root='a', pos='DT')\n",
      "WordNode(raw='different', root='different', pos='JJ')\n",
      "WordNode(raw='mix', root='mix', pos='NN')\n",
      "WordNode(raw='of', root='of', pos='IN')\n",
      "WordNode(raw='people', root='people', pos='NNS')\n",
      "WordNode(raw='.', root='.', pos='.')\n",
      "WordNode(raw='For', root='for', pos='IN')\n",
      "WordNode(raw='v1.0', root='v1.0', pos='NN')\n",
      "WordNode(raw=',', root=',', pos='.')\n",
      "WordNode(raw='we', root='we', pos='PRP')\n",
      "WordNode(raw='heard', root='hear', pos='VBD')\n",
      "WordNode(raw='almost', root='almost', pos='RB')\n",
      "WordNode(raw='exclusively', root='exclusively', pos='RB')\n",
      "WordNode(raw='from', root='from', pos='IN')\n",
      "WordNode(raw='founders', root='founder', pos='NNS')\n",
      "WordNode(raw='and', root='and', pos='CC')\n",
      "WordNode(raw='academics', root='academic', pos='NNS')\n",
      "WordNode(raw='.', root='.', pos='.')\n",
      "WordNode(raw='Then', root='then', pos='RB')\n",
      "WordNode(raw='came', root='come', pos='VBD')\n",
      "WordNode(raw='a', root='a', pos='DT')\n",
      "WordNode(raw='healthy', root='healthy', pos='JJ')\n",
      "WordNode(raw='mix', root='mix', pos='NN')\n",
      "WordNode(raw='of', root='of', pos='IN')\n",
      "WordNode(raw='investors', root='investor', pos='NNS')\n",
      "WordNode(raw=',', root=',', pos='.')\n",
      "WordNode(raw='both', root='both', pos='DT')\n",
      "WordNode(raw='private', root='private', pos='JJ')\n",
      "WordNode(raw='and', root='and', pos='CC')\n",
      "WordNode(raw='public', root='public', pos='JJ')\n",
      "WordNode(raw='.', root='.', pos='.')\n",
      "WordNode(raw='Now', root='now', pos='RB')\n",
      "WordNode(raw='overwhelmingly', root='overwhelmingly', pos='RB')\n",
      "WordNode(raw='we', root='we', pos='PRP')\n",
      "WordNode(raw='have', root='have', pos='VBP')\n",
      "WordNode(raw='heard', root='hear', pos='VBN')\n",
      "WordNode(raw='from', root='from', pos='IN')\n",
      "WordNode(raw='existing', root='exist', pos='VBG')\n",
      "WordNode(raw='companies', root='company', pos='NNS')\n",
      "WordNode(raw='trying', root='try', pos='VBG')\n",
      "WordNode(raw='to', root='to', pos='TO')\n",
      "WordNode(raw='figure', root='figure', pos='VB')\n",
      "WordNode(raw='out', root='out', pos='RP')\n",
      "WordNode(raw='how', root='how', pos='WRB')\n",
      "WordNode(raw='to', root='to', pos='TO')\n",
      "WordNode(raw='transform', root='transform', pos='VB')\n",
      "WordNode(raw='their', root='their', pos='PRP$')\n",
      "WordNode(raw='businesses', root='business', pos='NNS')\n",
      "WordNode(raw='using', root='use', pos='VBG')\n",
      "WordNode(raw='machine', root='machine', pos='NN')\n",
      "WordNode(raw='intelligence', root='intelligence', pos='NN')\n",
      "WordNode(raw='.', root='.', pos='.')\n"
     ]
    }
   ],
   "source": [
    "json_file = \"a1.json\"\n",
    "\n",
    "for lex in pynlp.lex_iter(json_file):\n",
    "  print(lex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "foo bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "files = [\"a4.json\", \"a3.json\", \"a2.json\", \"a1.json\"]\n",
    "files_tf = {}\n",
    "\n",
    "d = len(files)\n",
    "df = defaultdict(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "foo bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a1.json defaultdict(<class 'int'>, {'continue': 1, 'lot': 1, 'private': 1, 'third': 1, 'software': 1, 'now-annual': 1, 'exist': 1, 'first': 2, 'last': 2, 'couple': 1, 'investor': 1, 'inbound': 1, 'even': 1, 'hyped': 1, 'biggest': 1, 'thoughtfully': 1, 'case': 1, 'recruit': 1, 'others': 1, 'goodness': 1, 'intelligence': 6, 'right': 1, 'activity': 2, 'invest': 2, 'technology': 1, 'hear': 2, 'ago': 2, 'machine': 6, 'publish': 1, 'word': 1, 'surface': 1, 'grow': 1, 'comprehensive': 1, 'healthy': 1, 'scratch': 1, 'company': 4, 'landscape': 2, 'business': 1, 'transform': 1, 'breakthrough': 1, 'deep': 1, 'year': 5, 'data': 1, 'fanciest': 1, 'time': 1, 'wonderful': 1, 'area': 1, '35': 2, 'method': 2, 'figure': 1, 'learning': 1, 'phrase': 1, 'public': 1, 'different': 1, 'almost': 2, 'care': 1, 'those': 1, 'founder': 2, 'change': 1, 'apply': 1, 'exclusively': 1, 'domains': 1, 'still': 1, 'security': 1, 'v1.0': 1, 'obsess': 1, 'mix': 2, 'inquiry': 1, 'fund': 2, 'people': 1, 'work': 1, 'whether': 1, 'problem': 3, 'overwhelmingly': 1, 'future': 1, 'series': 1, 'big': 1, 'equally': 1, 'good': 1, 'development': 1, 'hype': 1, 'focus': 1, 'favor': 1, 'solve': 2, 'represent': 1, 'academic': 1, 'futile': 1, 'meaningful': 2})\n"
     ]
    }
   ],
   "source": [
    "for json_file in files:\n",
    "  tf = defaultdict(int)\n",
    "\n",
    "  for lex in pynlp.lex_iter(json_file):\n",
    "    if (lex.pos != \".\") and (lex.root not in stopwords):\n",
    "      tf[lex.root] += 1\n",
    "\n",
    "  files_tf[json_file] = tf\n",
    "\n",
    "  for word in tf.keys():\n",
    "    df[word] += 1\n",
    "\n",
    "print(json_file, files_tf[json_file])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "foo bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning 4\n",
      "machine 3\n",
      "learn 3\n",
      "year 3\n",
      "time 3\n",
      "many 2\n",
      "publish 2\n",
      "company 2\n",
      "programming 2\n",
      "early 2\n",
      "problem 2\n",
      "solve 2\n",
      "biggest 2\n",
      "provide 2\n",
      "local 2\n",
      "work 2\n",
      "feedback 2\n",
      "training 2\n",
      "book 2\n",
      "past 2\n",
      "interact 2\n",
      "step 2\n",
      "apply 2\n",
      "thing 2\n",
      "data 2\n",
      "exist 2\n",
      "o'reilly 2\n",
      "attendance 2\n",
      "open 2\n",
      "deep 2\n",
      "first 2\n",
      "whether 2\n",
      "become 2\n",
      "student 2\n",
      "post 2\n",
      "people 2\n",
      "start 2\n",
      "bit 1\n",
      "0.4 1\n",
      "instructional 1\n",
      "extremely 1\n",
      "defacto 1\n",
      "one-way 1\n",
      "easy 1\n",
      "primary 1\n",
      "barrier 1\n",
      "remember 1\n",
      "issue 1\n",
      "clear 1\n",
      "heart 1\n",
      "guidance 1\n",
      "even 1\n",
      "lead 1\n",
      "lot 1\n",
      "resistant 1\n",
      "camp 1\n",
      "analyze 1\n",
      "matei 1\n",
      "streaming 1\n",
      "special 1\n",
      "founder 1\n",
      "weight 1\n",
      "applies 1\n",
      "bring 1\n",
      "progress 1\n",
      "mainstream 1\n",
      "look 1\n",
      "word 1\n",
      "mahout 1\n",
      "polynomial 1\n",
      "fan 1\n",
      "healthy 1\n",
      "enthusiasm 1\n",
      "example 1\n",
      "business 1\n",
      "sum 1\n",
      "suggest 1\n",
      "theory 1\n",
      "finally 1\n",
      "processing 1\n",
      "scratch 1\n",
      "global 1\n",
      "35 1\n",
      "computer 1\n",
      "pyspark 1\n",
      "pass 1\n",
      "most 1\n",
      "user 1\n",
      "scientist 1\n",
      "last 1\n",
      "professor 1\n",
      "care 1\n",
      "recent 1\n",
      "zaharia 1\n",
      "pig 1\n",
      "development 1\n",
      "feature 1\n",
      "following 1\n",
      "usage 1\n",
      "hit 1\n",
      "almost 1\n",
      "difficulty 1\n",
      "obsess 1\n",
      "mix 1\n",
      "inquiry 1\n",
      "later 1\n",
      "ongoing 1\n",
      "fund 1\n",
      "breakthrough 1\n",
      "investor 1\n",
      "important 1\n",
      "equally 1\n",
      "hyped 1\n",
      "50 1\n",
      "hype 1\n",
      "think 1\n",
      "np-hard 1\n",
      "rich 1\n",
      "continue 1\n",
      "happen 1\n",
      "course 1\n",
      "preview 1\n",
      "change 1\n",
      "fanciest 1\n",
      "because 1\n",
      "software 1\n",
      "now-annual 1\n",
      "speed 1\n",
      "san 1\n",
      "initial 1\n",
      "one-shot 1\n",
      "arises 1\n",
      "say 1\n",
      "day 1\n",
      "fortunate 1\n",
      "audience 1\n",
      "give 1\n",
      "why 1\n",
      "useful 1\n",
      "plan 1\n",
      "1990s 1\n",
      "hive 1\n",
      "participate 1\n",
      "case 1\n",
      "exam 1\n",
      "similar 1\n",
      "enough 1\n",
      "right 1\n",
      "release 1\n",
      "team 1\n",
      "technology 1\n",
      "hands-on 1\n",
      "indeed 1\n",
      "overcome 1\n",
      "background 1\n",
      "meetups 1\n",
      "hard 1\n",
      "wise 1\n",
      "reason 1\n",
      "clearly 1\n",
      "necessary 1\n",
      "jvm 1\n",
      "mean 1\n",
      "back 1\n",
      "seasoned 1\n",
      "me 1\n",
      "classroom 1\n",
      "transform 1\n",
      "beginning 1\n",
      "single-node 1\n",
      "infrastructure 1\n",
      "evaluate 1\n",
      "stand 1\n",
      "explore 1\n",
      "activity 1\n",
      "project 1\n",
      "wonderful 1\n",
      "classify 1\n",
      "scala 1\n",
      "2012 1\n",
      "below 1\n",
      "phrase 1\n",
      "public 1\n",
      "deeper 1\n",
      "talk 1\n",
      "experienced 1\n",
      "soon 1\n",
      "live 1\n",
      "exclusively 1\n",
      "focus 1\n",
      "introduction 1\n",
      "standard 1\n",
      "every 1\n",
      "domains 1\n",
      "gain 1\n",
      "layer 1\n",
      "security 1\n",
      "add 1\n",
      "prominently 1\n",
      "seven 1\n",
      "particular 1\n",
      "better 1\n",
      "library 1\n",
      "due 1\n",
      "play 1\n",
      "popular 1\n",
      "single-layer 1\n",
      "mid 1\n",
      "future 1\n",
      "medium 1\n",
      "hang 1\n",
      "good 1\n",
      "myself 1\n",
      "during 1\n",
      "addict 1\n",
      "decade 1\n",
      "advice 1\n",
      "meaningful 1\n",
      "algorithm 1\n",
      "event 1\n",
      "keep 1\n",
      "individual 1\n",
      "help 1\n",
      "second 1\n",
      "video 1\n",
      "instructor 1\n",
      "always 1\n",
      "together 1\n",
      "overwhelmingly 1\n",
      "several 1\n",
      "nice 1\n",
      "reaction 1\n",
      "thoughtfully 1\n",
      "recruit 1\n",
      "others 1\n",
      "question 1\n",
      "intelligence 1\n",
      "very 1\n",
      "situation 1\n",
      "long 1\n",
      "ago 1\n",
      "simplified 1\n",
      "immediately 1\n",
      "2000s 1\n",
      "steady 1\n",
      "grow 1\n",
      "comprehensive 1\n",
      "friend 1\n",
      "neural 1\n",
      "unveiling 1\n",
      "provably 1\n",
      "experience 1\n",
      "correctly 1\n",
      "amp 1\n",
      "java 1\n",
      "draw 1\n",
      "landscape 1\n",
      "decline 1\n",
      "optimize 1\n",
      "make 1\n",
      "set 1\n",
      "everyone 1\n",
      "area 1\n",
      "2016 1\n",
      "minimum 1\n",
      "fall 1\n",
      "addition 1\n",
      "simplest 1\n",
      "figure 1\n",
      "group 1\n",
      "subset 1\n",
      "edge 1\n",
      "location 1\n",
      "saw 1\n",
      "n-node 1\n",
      "process 1\n",
      "ability 1\n",
      "invite 1\n",
      "co-worker 1\n",
      "community 1\n",
      "python 1\n",
      "assess 1\n",
      "unfortunately 1\n",
      "still 1\n",
      "optimization 1\n",
      "batch 1\n",
      "roll 1\n",
      "meetup 1\n",
      "in-person 1\n",
      "contribute 1\n",
      "variety 1\n",
      "introduce 1\n",
      "attractive 1\n",
      "reader 1\n",
      "loop 1\n",
      "involve 1\n",
      "perceptron 1\n",
      "knowledge 1\n",
      "conversation 1\n",
      "v1.0 1\n",
      "linear 1\n",
      "virtual 1\n",
      "clojure 1\n",
      "survey 1\n",
      "academic 1\n",
      "futile 1\n",
      "nutshell 1\n",
      "convex 1\n",
      "private 1\n",
      "would 1\n",
      "third 1\n",
      "title 1\n",
      "hope 1\n",
      "prospect 1\n",
      "physical 1\n",
      "interest 1\n",
      "gather 1\n",
      "couple 1\n",
      "researcher 1\n",
      "whose 1\n",
      "inbound 1\n",
      "big 1\n",
      "general 1\n",
      "j. 1\n",
      "polynomial-time 1\n",
      "stephen 1\n",
      "spark 1\n",
      "discover 1\n",
      "cloud-friendly 1\n",
      "goodness 1\n",
      "love 1\n",
      "potential 1\n",
      "those 1\n",
      "hear 1\n",
      "1988 1\n",
      "pace 1\n",
      "network 1\n",
      "realize 1\n",
      "judd 1\n",
      "0.5 1\n",
      "stream 1\n",
      "natural 1\n",
      "guarantee 1\n",
      "shoulder 1\n",
      "thousand 1\n",
      "surface 1\n",
      "aws 1\n",
      "language 1\n",
      "optimal 1\n",
      "author 1\n",
      "neuron 1\n",
      "number 1\n",
      "broach 1\n",
      "graphic 1\n",
      "show 1\n",
      "online 1\n",
      "include 1\n",
      "hardness 1\n",
      "harder 1\n",
      "version 1\n",
      "combine 1\n",
      "begin 1\n",
      "presentation 1\n",
      "francisco 1\n",
      "lie 1\n",
      "single 1\n",
      "enroute 1\n",
      "different 1\n",
      "well 1\n",
      "large 1\n",
      "method 1\n",
      "idea 1\n",
      "conference 1\n",
      "storm 1\n",
      "amplab 1\n",
      "tool 1\n",
      "immediate 1\n",
      "developer 1\n",
      "attend 1\n",
      "editorial 1\n",
      "mid-'80s 1\n",
      "represent 1\n",
      "tutorial 1\n",
      "invest 1\n",
      "task 1\n",
      "series 1\n",
      "creator 1\n",
      "science 1\n",
      "after 1\n",
      "favor 1\n",
      "break 1\n",
      "n 1\n",
      "expert 1\n"
     ]
    }
   ],
   "source": [
    "for word, count in sorted(df.items(), key=lambda kv: kv[1], reverse=True):\n",
    "  print(word, count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "foo bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "for json_file in files:\n",
    "  tf = files_tf[json_file]\n",
    "  keywords = []\n",
    "\n",
    "  for word, count in tf.items():\n",
    "    tfidf = float(count) * math.log((d + 1.0) / (df[word] + 1.0))\n",
    "    keywords.append((json_file, tfidf, word,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "foo bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a1.json\t 5.4977\tintelligence\n",
      "a1.json\t 2.0433\tcompany\n",
      "a1.json\t 1.8326\tlast\n",
      "a1.json\t 1.8326\tactivity\n",
      "a1.json\t 1.8326\tinvest\n",
      "a1.json\t 1.8326\thear\n",
      "a1.json\t 1.8326\tago\n",
      "a1.json\t 1.8326\tlandscape\n",
      "a1.json\t 1.8326\t35\n",
      "a1.json\t 1.8326\tmethod\n",
      "a1.json\t 1.8326\talmost\n",
      "a1.json\t 1.8326\tfounder\n",
      "a1.json\t 1.8326\tmix\n",
      "a1.json\t 1.8326\tfund\n",
      "a1.json\t 1.8326\tmeaningful\n",
      "a1.json\t 1.5325\tproblem\n",
      "a1.json\t 1.3389\tmachine\n",
      "a1.json\t 1.1157\tyear\n",
      "a1.json\t 1.0217\tfirst\n",
      "a1.json\t 1.0217\tsolve\n",
      "a1.json\t 0.9163\tcontinue\n",
      "a1.json\t 0.9163\tlot\n",
      "a1.json\t 0.9163\tprivate\n",
      "a1.json\t 0.9163\tthird\n",
      "a1.json\t 0.9163\tsoftware\n",
      "a1.json\t 0.9163\tnow-annual\n",
      "a1.json\t 0.9163\tcouple\n",
      "a1.json\t 0.9163\tinvestor\n",
      "a1.json\t 0.9163\tinbound\n",
      "a1.json\t 0.9163\teven\n",
      "a1.json\t 0.9163\thyped\n",
      "a1.json\t 0.9163\tthoughtfully\n",
      "a1.json\t 0.9163\tcase\n",
      "a1.json\t 0.9163\trecruit\n",
      "a1.json\t 0.9163\tothers\n",
      "a1.json\t 0.9163\tgoodness\n",
      "a1.json\t 0.9163\tright\n",
      "a1.json\t 0.9163\ttechnology\n",
      "a1.json\t 0.9163\tword\n",
      "a1.json\t 0.9163\tsurface\n",
      "a1.json\t 0.9163\tgrow\n",
      "a1.json\t 0.9163\tcomprehensive\n",
      "a1.json\t 0.9163\thealthy\n",
      "a1.json\t 0.9163\tscratch\n",
      "a1.json\t 0.9163\tbusiness\n",
      "a1.json\t 0.9163\ttransform\n",
      "a1.json\t 0.9163\tbreakthrough\n",
      "a1.json\t 0.9163\tfanciest\n",
      "a1.json\t 0.9163\twonderful\n",
      "a1.json\t 0.9163\tarea\n",
      "a1.json\t 0.9163\tfigure\n",
      "a1.json\t 0.9163\tphrase\n",
      "a1.json\t 0.9163\tpublic\n",
      "a1.json\t 0.9163\tdifferent\n",
      "a1.json\t 0.9163\tcare\n",
      "a1.json\t 0.9163\tthose\n",
      "a1.json\t 0.9163\tchange\n",
      "a1.json\t 0.9163\texclusively\n",
      "a1.json\t 0.9163\tdomains\n",
      "a1.json\t 0.9163\tstill\n",
      "a1.json\t 0.9163\tsecurity\n",
      "a1.json\t 0.9163\tv1.0\n",
      "a1.json\t 0.9163\tobsess\n",
      "a1.json\t 0.9163\tinquiry\n",
      "a1.json\t 0.9163\toverwhelmingly\n",
      "a1.json\t 0.9163\tfuture\n",
      "a1.json\t 0.9163\tseries\n",
      "a1.json\t 0.9163\tbig\n",
      "a1.json\t 0.9163\tequally\n",
      "a1.json\t 0.9163\tgood\n",
      "a1.json\t 0.9163\tdevelopment\n",
      "a1.json\t 0.9163\thype\n",
      "a1.json\t 0.9163\tfocus\n",
      "a1.json\t 0.9163\tfavor\n",
      "a1.json\t 0.9163\trepresent\n",
      "a1.json\t 0.9163\tacademic\n",
      "a1.json\t 0.9163\tfutile\n",
      "a1.json\t 0.5108\texist\n",
      "a1.json\t 0.5108\tbiggest\n",
      "a1.json\t 0.5108\tpublish\n",
      "a1.json\t 0.5108\tdeep\n",
      "a1.json\t 0.5108\tdata\n",
      "a1.json\t 0.5108\tapply\n",
      "a1.json\t 0.5108\tpeople\n",
      "a1.json\t 0.5108\twork\n",
      "a1.json\t 0.5108\twhether\n",
      "a1.json\t 0.2231\ttime\n",
      "a1.json\t 0.0000\tlearning\n"
     ]
    }
   ],
   "source": [
    "for json_file, tfidf, word in sorted(keywords, key=lambda x: x[1], reverse=True):\n",
    "  print(\"%s\\t%7.4f\\t%s\" % (json_file, tfidf, word))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
